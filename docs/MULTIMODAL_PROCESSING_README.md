# Multi-Modal Legal Document Processing

## Overview

The Multi-Modal Legal Document Processing system is an advanced enhancement to the LegalizeMe AI platform, designed to process legal PDFs, images (scanned documents), and long-form text with intelligent extraction, summarization, and analysis capabilities.

## üèóÔ∏è Architecture

### Core Components

1. **MultiModalDocumentProcessor** (`app/services/advanced_multimodal/document_processor.py`)
   - Enhanced PDF text extraction with multiple fallback methods
   - Advanced OCR processing for images with preprocessing
   - Document type detection using pattern matching
   - AWS Bedrock integration for summarization

2. **DocumentRouter** (`app/services/advanced_multimodal/document_router.py`)
   - Intelligent document type inference
   - Routing to appropriate processors
   - Post-processing analysis and quality assessment

3. **ImageOCRUtils** (`app/utils/ocr/image_ocr_utils.py`)
   - Specialized OCR utilities for legal documents
   - Document-specific preprocessing settings
   - Multiple OCR configuration testing

## üöÄ Features

### Document Processing Capabilities

- **PDF Processing**: pdfplumber (primary) ‚Üí pypdf2 (fallback) ‚Üí OCR (final fallback)
- **Image OCR**: Enhanced preprocessing with noise reduction, contrast enhancement, and adaptive thresholding
- **Document Type Detection**: Pattern-based classification for employment contracts, affidavits, judgments, legislation, etc.
- **Structured Summarization**: AWS Bedrock Claude/Mistral integration with JSON output
- **Entity Extraction**: Legal entities, dates, amounts, references, locations

### Supported Document Types

- Employment Contracts
- Affidavits
- Court Judgments
- Legislation
- Constitutional Documents
- Civil Cases
- General Legal Documents

### Supported File Formats

- PDF (.pdf)
- Images (.png, .jpg, .jpeg, .tiff, .bmp)
- Word Documents (.docx) - *planned*
- Plain Text (.txt)

## üìã API Reference

### MultiModalDocumentProcessor

#### `extract_text_from_pdf(file_path: Path) -> Dict[str, Any]`

Enhanced PDF text extraction with multiple fallback methods.

**Input:**
- `file_path`: Path to PDF file

**Output:**
```json
{
  "success": true,
  "text": "Extracted text content...",
  "extraction_method": "pdfplumber",
  "word_count": 1250,
  "char_count": 7500,
  "metadata": {
    "total_pages": 5,
    "has_tables": true
  }
}
```

#### `ocr_image_to_text(image_path: Path) -> Dict[str, Any]`

Enhanced OCR processing for images with preprocessing.

**Input:**
- `image_path`: Path to image file

**Output:**
```json
{
  "success": true,
  "text": "OCR extracted text...",
  "confidence": 87.5,
  "config_used": "single_column",
  "word_count": 450,
  "char_count": 2800,
  "extraction_method": "enhanced_ocr"
}
```

#### `detect_document_type(text: str) -> str`

Detect document type using pattern matching.

**Input:**
- `text`: Document text content

**Output:**
- Document type string: `"employment_contract"`, `"affidavit"`, `"judgment"`, etc.

#### `summarize_text(text: str, model: str = "claude-sonnet-4") -> Dict[str, Any]`

Generate structured summary using AWS Bedrock.

**Input:**
- `text`: Text to summarize
- `model`: Bedrock model to use

**Output:**
```json
{
  "success": true,
  "summary": "Brief summary of the document...",
  "document_type": "employment_contract",
  "key_parties": ["ABC Company", "John Doe"],
  "important_dates": ["2024-01-15", "2024-02-01"],
  "key_clauses": ["termination", "confidentiality"],
  "legal_references": ["Employment Act 2007"],
  "extracted_entities": {
    "parties": ["ABC Company", "John Doe"],
    "amounts": ["KSh 150,000"],
    "dates": ["15th January 2024"]
  },
  "model_used": "claude-sonnet-4"
}
```

### DocumentRouter

#### `process_document(file_path: Path, processing_options: Dict) -> Dict[str, Any]`

Main entry point for intelligent document processing.

**Input:**
- `file_path`: Path to document file
- `processing_options`: Processing configuration

**Output:**
```json
{
  "success": true,
  "text": "Document content...",
  "document_type": "employment_contract",
  "summary_data": { /* Summary results */ },
  "routing_info": {
    "file_type": "pdf",
    "file_size": 1048576,
    "processing_timestamp": "2024-01-20T10:30:00",
    "processor_used": "MultiModalDocumentProcessor"
  },
  "text_quality": {
    "word_count": 1250,
    "legal_document_score": 0.85
  },
  "processing_recommendations": [
    "High legal content detected - consider legal expert review"
  ]
}
```

## üîß Installation & Setup

### Dependencies

Add to `requirements.txt`:
```
pdfplumber>=0.11.0
pytesseract>=0.3.10
Pillow>=10.0.0
```

### System Requirements

1. **Tesseract OCR**: Install tesseract-ocr system package
2. **AWS Credentials**: Configure for Bedrock access
3. **Python Packages**: Install enhanced dependencies

### Configuration

Set environment variables:
```bash
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=us-east-1
AWS_BEDROCK_MODEL_ID_PRIMARY=us.anthropic.claude-sonnet-4-20250514-v1:0
```

## üß™ Testing

### Run Test Suite

```bash
python multimodal_test.py
```

### Test Coverage

- Processor initialization
- Router functionality
- OCR capabilities
- Document type detection
- PDF processing
- Image OCR processing
- Text summarization
- Integration testing

### Sample Documents

Place test files in `data/samples/`:
- `employment_contract_sample.pdf`
- `scanned_affidavit.png`
- `civil_case_summary.docx`

## üîó Integration Plans

### Phase 3: RAG Integration
- Connect to existing ChromaDB vector search
- Enhanced document indexing with multi-modal content
- Cross-reference capabilities

### Future Enhancements
- Entity recognition with NER models
- Contract clause mapping
- Legal taxonomy classification
- Multi-language support
- Advanced table extraction

### API Endpoint Integration
```python
@router.post("/counsel/process-document")
async def process_document(file: UploadFile = File(...)):
    router = DocumentRouter()
    result = await router.process_document(file_path)
    return result
```

## üìä Performance Metrics

### Processing Speed
- PDF (10 pages): ~5-15 seconds
- Image OCR: ~10-30 seconds per page
- Text summarization: ~5-10 seconds

### Accuracy
- PDF text extraction: 95%+ for text-based PDFs
- OCR accuracy: 80-95% depending on image quality
- Document type detection: 85%+ for legal documents

## üõ°Ô∏è Security Considerations

- File size limits: 100MB maximum
- Supported file types validation
- Temporary file cleanup
- AWS credentials security
- Input sanitization

## üîç Troubleshooting

### Common Issues

1. **OCR Not Available**
   - Install tesseract-ocr system package
   - Verify pytesseract installation

2. **Bedrock Access Denied**
   - Check AWS credentials
   - Verify Bedrock model access permissions

3. **Poor OCR Results**
   - Check image quality and resolution
   - Try different document type settings

### Debug Mode

Enable detailed logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## üìà Monitoring

### Key Metrics
- Processing success rate
- Average processing time
- OCR confidence scores
- Bedrock API usage
- Error rates by document type

### Logging
- Processing timestamps
- Error details
- Performance metrics
- Quality assessments

## ü§ù Contributing

1. Follow existing code patterns
2. Add comprehensive tests
3. Update documentation
4. Ensure AWS Bedrock compatibility
5. Test with sample legal documents

## üìÑ License

Part of the LegalizeMe AI Platform - Kenya's Legal AI Solution
